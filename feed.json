[


  
    
    {
      "title": "Jobstreet Scraper",
      "permalink": "http://0.0.0.0:4321/Scraping-Jobstreet-Posts.html",
      "link": "http://0.0.0.0:4321/Scraping-Jobstreet-Posts.html",
      "date": "2021-04-12T00:00:00+08:00",
      
        "modified": "2021-04-16T13:01:10+08:00",
      
      "author": {
        "name": "Naelah Nordin",
        "url": "https://naelahnordin.com/",
        "email": "naelahnordin@gmail.com"
      },
      "content": "<p>Each website is built by different individuals so there is no one magic script that can scrape different websites because the art of scraping lies in deconstructing the html elements into separate objects that we can extract or “scrape” the information from. Of course there are scraping tools out there that automate these scripts based on your preference (literally google free web scraping tools, there are a bunch of them). I have tried several of these tools and I always end up getting frustrated and going back to writing the codes myself because a) they always have a pricing tier despite claiming to be free, and b) the process is overcomplicated and some websites are just not built intuitively that these tools can easily automate. This tutorial specifies the necessary steps to scrape data from Jobstreet Malaysia but the process of crawling and scraping boils down to a few basic steps that can be applied to almost any website.</p>\n\n<h1 id=\"web-scraping-vs-web-crawling\">Web Scraping vs. Web Crawling</h1>\n\n<p>These two terms get thrown out a lot when it comes to automating data acquisition from the internet. Sometimes it is used interchangably to mean the same thing but they are actually different methods that are used together in achieving the same goal which is to extract information from a website that is presented in a way that has a pattern. This pattern is the key in writing codes that can iterate from one page to another. For example let’s look at jobstreet’s search page.</p>\n\n<p class=\"browser\"><img src=\"assets/img/jobstreet-screenshot-1.png\" alt=\"Image\" /></p>\n\n<p>There are several patterns here that we can leverage on. At this point you have to ask yourself, how do I get all these links? If you weren’t aiming to crawl and to scrape, how would you manually do it? In this example, jobstreet provides a paginated result page. There are a fixed amount of number of links in each page and they are all in similar looking boxes which suggests that the styling would use the same ID, this is important for scraping later, but as for now, in order to crawl and get all the relevant links, you need to determine how the data is populated.</p>\n\n<p>Another example is Facebook which does not have pagination, on the contrary it uses infinite scrolling so the method of crawling is completely different. Even if a website has pagination, we need to determine how the website processes user input and goes to the next page. Most commonly, websites implement URL parameters which means the number of page is in the url like <code class=\"language-plaintext highlighter-rouge\">www.website.com?page=2</code> or <code class=\"language-plaintext highlighter-rouge\">www.website.com/2/</code>. In these cases, going from one page to another is pretty straightforward. However, some websites implementing things like servlets and do not take parameters in the URL are trickier to crawl but still possible. You can maybe imitate certain buttons clicking or imitate scrolling, anything is possible.</p>\n\n<ol>\n  <li>\n    <p>Search keyword is appended in the url</p>\n\n    <p>Because jobstreet uses URL parameters, it’s just a matter of modifying the URL in each iteration. Here we can also see that the keyword is appended at the end of the URL as such, <code class=\"language-plaintext highlighter-rouge\">www.jobstreet.com.my/en/job-search/data-jobs</code>, this allows for querying multiple keywords.</p>\n  </li>\n  <li>\n    <p>There are 1832 job postings, with 30 jobs listed on each page</p>\n\n    <p>This means we only need math to determine how many iterations we need to go through all pages. We determine the class name of the text <code class=\"language-plaintext highlighter-rouge\">1832 jobs</code> by inspecting the element and from there we can simply do the following</p>\n  </li>\n</ol>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"kn\">import</span> <span class=\"nn\">math</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">get_page_number</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"p\">):</span>\n    <span class=\"c1\"># assuming total_jobs is processed and converted to integer\n</span>    <span class=\"c1\"># total_jobs divide by 30 pages and take the ceiling\n</span>    <span class=\"n\">page_number</span> <span class=\"o\">=</span> <span class=\"n\">math</span><span class=\"p\">.</span><span class=\"n\">ceil</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"o\">/</span><span class=\"mi\">30</span><span class=\"p\">)</span>\n<span class=\"k\">return</span> <span class=\"n\">page_number</span></code></pre></figure>\n\n<p>So now we have the page number, 8 which allows us to crawl all 8 page results and scrape the relevant links.</p>\n\n<h1 id=\"is-it-legal\">Is it Legal?</h1>\n\n<p>The short answer is an astounding <strong>Yes!</strong> We are not hacking into anyone’s private account. We are simply automating the process of one person manually clicking through a website 200 times and copying and pasting information, into a program that we can leave for hours and maybe days that would ultimately save our time but has no damaging consequences to the website owners. Ethically though, what we do with the information is another issue and the fact that scraping as a tool for morally ambiguous activity is up for debate, like how <a href=\"https://www.metro.us/everything-to-know-about-facemash-the-site-zuckerberg-created-in-college-to-rank-hot-women/\">Mark Zuckerberg scraped images of women in sorority houses in Harvard</a> to create a website comparing which woman is hotter is unanimously frowned upon but it is 100% legal.</p>\n\n<h1 id=\"getting-started\">Getting Started</h1>\n\n<p>To run the script, simply</p>\n\n<ol>\n  <li>Clone <a href=\"https://github.com/naelah/jobstreet-scraper\">this Github repository</a></li>\n  <li>Create a virtual python environment (optional). Run the following script in terminal\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>python -m venv venv\nsource venv/bin/activate\n</code></pre></div>    </div>\n  </li>\n  <li>Once the environment is activated, install the requirements\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>pip install -r requirements.txt\n</code></pre></div>    </div>\n  </li>\n  <li>Download <a href=\"https://chromedriver.chromium.org/\">chromedriver</a> based on your chrome version and  <a href=\"https://stackoverflow.com/questions/4423061/view-http-headers-in-google-chrome\">determine your version and header here</a></li>\n  <li>Modify <code class=\"language-plaintext highlighter-rouge\">jobstreet_scraper.py</code> accordingly</li>\n</ol>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"c1\"># Modify headers to match your device\n</span><span class=\"n\">headers</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s\">'User-Agent'</span><span class=\"p\">:</span><span class=\"s\">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36'</span><span class=\"p\">}</span>\n\n<span class=\"c1\"># Insert path to your chromedriver here\n</span><span class=\"n\">path</span> <span class=\"o\">=</span> <span class=\"s\">\"/usr/local/Caskroom/chromedriver/88.0.4324.96/chromedriver\"</span>\n<span class=\"p\">...</span>\n\n<span class=\"k\">def</span> <span class=\"nf\">main</span><span class=\"p\">():</span>\n\n    <span class=\"c1\"># determine the keywords that you want to query, it can be one or more but must be in a list\n</span>    <span class=\"n\">key_words</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s\">'agriculture'</span><span class=\"p\">,</span><span class=\"s\">'crop'</span><span class=\"p\">]</span>\n    </code></pre></figure>\n\n<p>Run <code class=\"language-plaintext highlighter-rouge\">python jobstreet_scraper.py</code> in terminal and you should see the scraping process starting.</p>\n\n<h1 id=\"breakdown-of-functions\">Breakdown of functions</h1>\n<p>The script consists a few key steps in successfully crawling and scraping which are</p>\n\n<p><strong>1. Configure driver to browse web pages &amp; BeautifulSoup4 to scrape html codes</strong></p>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"c1\"># configuration\n</span><span class=\"n\">headers</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s\">'User-Agent'</span><span class=\"p\">:</span><span class=\"s\">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36'</span><span class=\"p\">}</span>\n<span class=\"n\">path</span> <span class=\"o\">=</span> <span class=\"s\">\"/usr/local/Caskroom/chromedriver/88.0.4324.96/chromedriver\"</span>\n<span class=\"n\">driver</span> <span class=\"o\">=</span> <span class=\"n\">Chrome</span><span class=\"p\">(</span><span class=\"n\">executable_path</span><span class=\"o\">=</span><span class=\"n\">path</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># url template accepting keyword and page number\n</span><span class=\"n\">base_url</span> <span class=\"o\">=</span> <span class=\"s\">\"https://www.jobstreet.com.my/en/job-search/{}-jobs/{}/\"</span>\n\n<span class=\"c1\"># url generation https://www.jobstreet.com.my/en/job-search/agriculture-jobs/1/\n</span><span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">base_url</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">keyword</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># visits the specified url\n</span><span class=\"n\">driver</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># parses html page into selectable elements\n</span><span class=\"n\">soup</span> <span class=\"o\">=</span> <span class=\"n\">BeautifulSoup</span><span class=\"p\">(</span><span class=\"n\">driver</span><span class=\"p\">.</span><span class=\"n\">page_source</span><span class=\"p\">,</span> <span class=\"s\">'html.parser'</span><span class=\"p\">)</span></code></pre></figure>\n\n<p><strong>2. Iterate through keywords</strong></p>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">key_words</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s\">'agriculture'</span><span class=\"p\">,</span><span class=\"s\">'crop'</span><span class=\"p\">]</span>\n<span class=\"n\">dfs</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n<span class=\"k\">for</span> <span class=\"n\">key</span> <span class=\"ow\">in</span> <span class=\"n\">key_words</span><span class=\"p\">:</span>\n    <span class=\"n\">key_df</span> <span class=\"o\">=</span> <span class=\"n\">page_crawler</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">)</span>\n    <span class=\"n\">dfs</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">key_df</span><span class=\"p\">)</span>\n    </code></pre></figure>\n\n<p><strong>2. Get Page number</strong></p>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"k\">def</span> <span class=\"nf\">get_page_number</span><span class=\"p\">(</span><span class=\"n\">keyword</span><span class=\"p\">):</span>\n    <span class=\"c1\">#input: keyword for job_postings\n</span>    <span class=\"c1\">#output: number of pages\n</span>\n    <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">base_url</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">keyword</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">driver</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span>\n    <span class=\"n\">soup</span> <span class=\"o\">=</span> <span class=\"n\">BeautifulSoup</span><span class=\"p\">(</span><span class=\"n\">driver</span><span class=\"p\">.</span><span class=\"n\">page_source</span><span class=\"p\">,</span> <span class=\"s\">'html.parser'</span><span class=\"p\">)</span>\n\n    <span class=\"n\">result_text</span> <span class=\"o\">=</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">find</span><span class=\"p\">(</span><span class=\"s\">\"span\"</span><span class=\"p\">,{</span><span class=\"s\">\"class\"</span><span class=\"p\">:</span> <span class=\"s\">\"FYwKg _2Bz3E C6ZIU_0 _1_nER_0 _2DNlq_0 _29m7__0 _1PM5y_0\"</span><span class=\"p\">})</span>\n    <span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">result_text</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">.</span><span class=\"n\">split</span><span class=\"p\">()</span>\n    <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">result_text</span><span class=\"p\">.</span><span class=\"n\">text</span><span class=\"p\">.</span><span class=\"n\">split</span><span class=\"p\">()[</span><span class=\"o\">-</span><span class=\"mi\">2</span><span class=\"p\">])</span>\n    <span class=\"n\">page_number</span> <span class=\"o\">=</span> <span class=\"n\">math</span><span class=\"p\">.</span><span class=\"n\">ceil</span><span class=\"p\">(</span><span class=\"n\">result</span><span class=\"o\">/</span><span class=\"mi\">30</span><span class=\"p\">)</span>\n    \n    <span class=\"k\">return</span> <span class=\"n\">page_number</span>\n    </code></pre></figure>\n\n<p><strong>3. Iterate through pages</strong></p>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"k\">def</span> <span class=\"nf\">page_crawler</span><span class=\"p\">(</span><span class=\"n\">keyword</span><span class=\"p\">):</span>\n    <span class=\"c1\"># input: keyword for job postings\n</span>    <span class=\"c1\"># output: dataframe of links scraped from each page\n</span>\n    <span class=\"c1\"># page number\n</span>    <span class=\"n\">page_number</span> <span class=\"o\">=</span> <span class=\"n\">get_page_number</span><span class=\"p\">(</span><span class=\"n\">keyword</span><span class=\"p\">)</span>\n    <span class=\"n\">job_links</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n    <span class=\"k\">for</span> <span class=\"n\">n</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">page_number</span><span class=\"p\">):</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">'Loading page {} ...'</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">base_url</span><span class=\"p\">.</span><span class=\"nb\">format</span><span class=\"p\">(</span><span class=\"n\">keyword</span><span class=\"p\">,</span> <span class=\"n\">n</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n        <span class=\"n\">driver</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span>\n        <span class=\"n\">soup</span> <span class=\"o\">=</span> <span class=\"n\">BeautifulSoup</span><span class=\"p\">(</span><span class=\"n\">driver</span><span class=\"p\">.</span><span class=\"n\">page_source</span><span class=\"p\">,</span> <span class=\"s\">'html.parser'</span><span class=\"p\">)</span>\n    \n        <span class=\"c1\">#extract all job links\n</span>        <span class=\"n\">links</span> <span class=\"o\">=</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">find_all</span><span class=\"p\">(</span><span class=\"s\">'a'</span><span class=\"p\">,{</span><span class=\"s\">'class'</span><span class=\"p\">:</span><span class=\"s\">'DvvsL_0 _1p9OP'</span><span class=\"p\">})</span>\n        <span class=\"n\">job_links</span> <span class=\"o\">+=</span> <span class=\"n\">links</span>\n \n    <span class=\"n\">jobs</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n    <span class=\"k\">for</span> <span class=\"n\">link</span> <span class=\"ow\">in</span> <span class=\"n\">job_links</span><span class=\"p\">:</span>\n        <span class=\"n\">job_link</span> <span class=\"o\">=</span> <span class=\"n\">link</span><span class=\"p\">[</span><span class=\"s\">'href'</span><span class=\"p\">].</span><span class=\"n\">strip</span><span class=\"p\">().</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s\">'?'</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n        <span class=\"n\">jobs</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">([</span><span class=\"n\">keyword</span><span class=\"p\">,</span> <span class=\"n\">job_link</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">job_page_scraper</span><span class=\"p\">(</span><span class=\"n\">job_link</span><span class=\"p\">))</span>\n\n    <span class=\"n\">result_df</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">jobs</span><span class=\"p\">,</span> <span class=\"n\">columns</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s\">'keyword'</span><span class=\"p\">,</span> <span class=\"s\">'link'</span><span class=\"p\">,</span> <span class=\"s\">'job_id'</span><span class=\"p\">,</span> <span class=\"s\">'job_title'</span><span class=\"p\">,</span> <span class=\"s\">'job_expired'</span><span class=\"p\">,</span> <span class=\"s\">'job_confidential'</span><span class=\"p\">,</span> <span class=\"s\">'job_salary_max'</span><span class=\"p\">,</span> <span class=\"s\">'job_salary_max'</span><span class=\"p\">,</span> <span class=\"s\">'job_salary_currency'</span><span class=\"p\">,</span> <span class=\"s\">'company'</span><span class=\"p\">,</span> <span class=\"s\">'job_post_date'</span><span class=\"p\">,</span> <span class=\"s\">'job_internship'</span><span class=\"p\">,</span> <span class=\"s\">'company_website'</span><span class=\"p\">,</span> <span class=\"s\">'company_avgProcessTime'</span><span class=\"p\">,</span> <span class=\"s\">'company_registrationNo'</span><span class=\"p\">,</span> <span class=\"s\">'company_workingHours'</span><span class=\"p\">,</span> <span class=\"s\">'company_facebook'</span><span class=\"p\">,</span> <span class=\"s\">'company_size'</span><span class=\"p\">,</span> <span class=\"s\">'company_dressCode'</span><span class=\"p\">,</span> <span class=\"s\">'company_nearbyLocations'</span><span class=\"p\">,</span> <span class=\"s\">'company_overview'</span><span class=\"p\">,</span> <span class=\"s\">'job_description'</span><span class=\"p\">,</span> <span class=\"s\">'job_summary'</span><span class=\"p\">,</span> <span class=\"s\">'job_requirement_career_level'</span><span class=\"p\">,</span> <span class=\"s\">'job_requirement_fieldOfStudy'</span><span class=\"p\">,</span> <span class=\"s\">'job_requirement_yearsOfExperience'</span><span class=\"p\">,</span> <span class=\"s\">'job_requirement_qualification'</span><span class=\"p\">,</span> <span class=\"s\">'job_requirement_skill'</span><span class=\"p\">,</span> <span class=\"s\">'job_employment_type'</span><span class=\"p\">,</span> <span class=\"s\">'job_languages'</span><span class=\"p\">,</span> <span class=\"s\">'job_benefits'</span><span class=\"p\">,</span> <span class=\"s\">'job_apply_url'</span><span class=\"p\">,</span> <span class=\"s\">'job_location_zipcode'</span><span class=\"p\">,</span> <span class=\"s\">'job_location'</span><span class=\"p\">,</span> <span class=\"s\">'job_country'</span><span class=\"p\">])</span>\n    <span class=\"k\">return</span> <span class=\"n\">result_df</span>\n    </code></pre></figure>\n\n<p><strong>4. Time delay to avoid suspicion</strong></p>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"kn\">import</span> <span class=\"nn\">time</span>\n\n<span class=\"n\">time</span><span class=\"p\">.</span><span class=\"n\">sleep</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span></code></pre></figure>\n\n<p><strong>5. Scrape relevant data</strong></p>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"k\">def</span> <span class=\"nf\">job_page_scraper</span><span class=\"p\">(</span><span class=\"n\">link</span><span class=\"p\">):</span>\n\n    <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"s\">\"https://www.jobstreet.com.my\"</span><span class=\"o\">+</span><span class=\"n\">link</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"scraping...\"</span><span class=\"p\">,</span> <span class=\"n\">url</span><span class=\"p\">)</span>\n    <span class=\"n\">driver</span><span class=\"p\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span>\n    <span class=\"n\">soup</span> <span class=\"o\">=</span> <span class=\"n\">BeautifulSoup</span><span class=\"p\">(</span><span class=\"n\">driver</span><span class=\"p\">.</span><span class=\"n\">page_source</span><span class=\"p\">,</span> <span class=\"s\">'html.parser'</span><span class=\"p\">)</span>\n\n    <span class=\"n\">scripts</span> <span class=\"o\">=</span> <span class=\"n\">soup</span><span class=\"p\">.</span><span class=\"n\">find_all</span><span class=\"p\">(</span><span class=\"s\">\"script\"</span><span class=\"p\">)</span>\n\n    <span class=\"k\">for</span> <span class=\"n\">script</span> <span class=\"ow\">in</span> <span class=\"n\">scripts</span><span class=\"p\">:</span>\n        <span class=\"k\">if</span> <span class=\"n\">script</span><span class=\"p\">.</span><span class=\"n\">contents</span><span class=\"p\">:</span>\n            <span class=\"n\">txt</span> <span class=\"o\">=</span> <span class=\"n\">script</span><span class=\"p\">.</span><span class=\"n\">contents</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">].</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n            <span class=\"k\">if</span> <span class=\"s\">'window.REDUX_STATE = '</span> <span class=\"ow\">in</span> <span class=\"n\">txt</span><span class=\"p\">:</span>\n                <span class=\"n\">jsonStr</span> <span class=\"o\">=</span> <span class=\"n\">script</span><span class=\"p\">.</span><span class=\"n\">contents</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">].</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n                <span class=\"n\">jsonStr</span> <span class=\"o\">=</span> <span class=\"n\">jsonStr</span><span class=\"p\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s\">'window.REDUX_STATE = '</span><span class=\"p\">)[</span><span class=\"mi\">1</span><span class=\"p\">].</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n                <span class=\"n\">jsonStr</span> <span class=\"o\">=</span> <span class=\"n\">jsonStr</span><span class=\"p\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s\">'}}}};'</span><span class=\"p\">)[</span><span class=\"mi\">0</span><span class=\"p\">].</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n                <span class=\"n\">jsonStr</span> <span class=\"o\">=</span> <span class=\"n\">jsonStr</span><span class=\"o\">+</span><span class=\"s\">\"}}}}\"</span>\n                <span class=\"n\">jsonObj</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"p\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">jsonStr</span><span class=\"p\">)</span>\n    \n    <span class=\"n\">job</span> <span class=\"o\">=</span> <span class=\"n\">jsonObj</span><span class=\"p\">[</span><span class=\"s\">'details'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_id</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'id'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_expired</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'isExpired'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_confidential</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'isConfidential'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_salary_min</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'header'</span><span class=\"p\">][</span><span class=\"s\">'salary'</span><span class=\"p\">][</span><span class=\"s\">'min'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_salary_max</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'header'</span><span class=\"p\">][</span><span class=\"s\">'salary'</span><span class=\"p\">][</span><span class=\"s\">'max'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_salary_currency</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'header'</span><span class=\"p\">][</span><span class=\"s\">'salary'</span><span class=\"p\">][</span><span class=\"s\">'currency'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_title</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'header'</span><span class=\"p\">][</span><span class=\"s\">'jobTitle'</span><span class=\"p\">]</span>\n    <span class=\"n\">company</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'header'</span><span class=\"p\">][</span><span class=\"s\">'company'</span><span class=\"p\">][</span><span class=\"s\">'name'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_post_date</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'header'</span><span class=\"p\">][</span><span class=\"s\">'postedDate'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_internship</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'header'</span><span class=\"p\">][</span><span class=\"s\">'isInternship'</span><span class=\"p\">]</span>\n    <span class=\"n\">company_website</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'companyDetail'</span><span class=\"p\">][</span><span class=\"s\">'companyWebsite'</span><span class=\"p\">]</span>\n    <span class=\"n\">company_avgProcessTime</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'companyDetail'</span><span class=\"p\">][</span><span class=\"s\">'companySnapshot'</span><span class=\"p\">][</span><span class=\"s\">'avgProcessTime'</span><span class=\"p\">]</span>\n    <span class=\"n\">company_registrationNo</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'companyDetail'</span><span class=\"p\">][</span><span class=\"s\">'companySnapshot'</span><span class=\"p\">][</span><span class=\"s\">'registrationNo'</span><span class=\"p\">]</span>\n    <span class=\"n\">company_workingHours</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'companyDetail'</span><span class=\"p\">][</span><span class=\"s\">'companySnapshot'</span><span class=\"p\">][</span><span class=\"s\">'workingHours'</span><span class=\"p\">]</span>\n    <span class=\"n\">company_facebook</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'companyDetail'</span><span class=\"p\">][</span><span class=\"s\">'companySnapshot'</span><span class=\"p\">][</span><span class=\"s\">'facebook'</span><span class=\"p\">]</span>\n    <span class=\"n\">company_size</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'companyDetail'</span><span class=\"p\">][</span><span class=\"s\">'companySnapshot'</span><span class=\"p\">][</span><span class=\"s\">'size'</span><span class=\"p\">]</span>\n    <span class=\"n\">company_dressCode</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'companyDetail'</span><span class=\"p\">][</span><span class=\"s\">'companySnapshot'</span><span class=\"p\">][</span><span class=\"s\">'dressCode'</span><span class=\"p\">]</span>\n    <span class=\"n\">company_nearbyLocations</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'companyDetail'</span><span class=\"p\">][</span><span class=\"s\">'companySnapshot'</span><span class=\"p\">][</span><span class=\"s\">'nearbyLocations'</span><span class=\"p\">]</span>\n    <span class=\"n\">company_overview</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'companyDetail'</span><span class=\"p\">][</span><span class=\"s\">'companyOverview'</span><span class=\"p\">][</span><span class=\"s\">'html'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_description</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'jobDescription'</span><span class=\"p\">][</span><span class=\"s\">'html'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_summary</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'summary'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_requirement_career_level</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'jobRequirement'</span><span class=\"p\">][</span><span class=\"s\">'careerLevel'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_requirement_yearsOfExperience</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'jobRequirement'</span><span class=\"p\">][</span><span class=\"s\">'yearsOfExperience'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_requirement_qualification</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'jobRequirement'</span><span class=\"p\">][</span><span class=\"s\">'qualification'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_requirement_fieldOfStudy</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'jobRequirement'</span><span class=\"p\">][</span><span class=\"s\">'fieldOfStudy'</span><span class=\"p\">]</span>\n    <span class=\"c1\">#job_requirement_industry = job['jobDetail']['jobRequirement']['industryValue']['label']\n</span>    <span class=\"n\">job_requirement_skill</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'jobRequirement'</span><span class=\"p\">][</span><span class=\"s\">'skills'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_employment_type</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'jobRequirement'</span><span class=\"p\">][</span><span class=\"s\">'employmentType'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_languages</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'jobRequirement'</span><span class=\"p\">][</span><span class=\"s\">'languages'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_benefits</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'jobDetail'</span><span class=\"p\">][</span><span class=\"s\">'jobRequirement'</span><span class=\"p\">][</span><span class=\"s\">'benefits'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_apply_url</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'applyUrl'</span><span class=\"p\">][</span><span class=\"s\">'url'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_location_zipcode</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'location'</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"s\">'locationId'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_location</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'location'</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"s\">'location'</span><span class=\"p\">]</span>\n    <span class=\"n\">job_country</span> <span class=\"o\">=</span> <span class=\"n\">job</span><span class=\"p\">[</span><span class=\"s\">'sourceCountry'</span><span class=\"p\">]</span>\n\n    <span class=\"k\">return</span> <span class=\"p\">[</span><span class=\"n\">job_id</span><span class=\"p\">,</span> <span class=\"n\">job_title</span><span class=\"p\">,</span> <span class=\"n\">job_expired</span><span class=\"p\">,</span> <span class=\"n\">job_confidential</span><span class=\"p\">,</span> <span class=\"n\">job_salary_max</span><span class=\"p\">,</span> <span class=\"n\">job_salary_max</span><span class=\"p\">,</span> <span class=\"n\">job_salary_currency</span><span class=\"p\">,</span> <span class=\"n\">company</span><span class=\"p\">,</span> <span class=\"n\">job_post_date</span><span class=\"p\">,</span> <span class=\"n\">job_internship</span><span class=\"p\">,</span> <span class=\"n\">company_website</span><span class=\"p\">,</span> <span class=\"n\">company_avgProcessTime</span><span class=\"p\">,</span> <span class=\"n\">company_registrationNo</span><span class=\"p\">,</span> <span class=\"n\">company_workingHours</span><span class=\"p\">,</span> <span class=\"n\">company_facebook</span><span class=\"p\">,</span> <span class=\"n\">company_size</span><span class=\"p\">,</span> <span class=\"n\">company_dressCode</span><span class=\"p\">,</span> <span class=\"n\">company_nearbyLocations</span><span class=\"p\">,</span> <span class=\"n\">company_overview</span><span class=\"p\">,</span> <span class=\"n\">job_description</span><span class=\"p\">,</span> <span class=\"n\">job_summary</span><span class=\"p\">,</span> <span class=\"n\">job_requirement_career_level</span><span class=\"p\">,</span> <span class=\"n\">job_requirement_fieldOfStudy</span><span class=\"p\">,</span> <span class=\"n\">job_requirement_yearsOfExperience</span><span class=\"p\">,</span> <span class=\"n\">job_requirement_qualification</span><span class=\"p\">,</span> <span class=\"n\">job_requirement_skill</span><span class=\"p\">,</span> <span class=\"n\">job_employment_type</span><span class=\"p\">,</span> <span class=\"n\">job_languages</span><span class=\"p\">,</span> <span class=\"n\">job_benefits</span><span class=\"p\">,</span> <span class=\"n\">job_apply_url</span><span class=\"p\">,</span> <span class=\"n\">job_location_zipcode</span><span class=\"p\">,</span> <span class=\"n\">job_location</span><span class=\"p\">,</span> <span class=\"n\">job_country</span><span class=\"p\">]</span></code></pre></figure>\n\n<p><strong>6. save data</strong></p>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"c1\"># concatenate dataframes and save scraped information as csv\n</span><span class=\"n\">pd</span><span class=\"p\">.</span><span class=\"n\">concat</span><span class=\"p\">(</span><span class=\"n\">dfs</span><span class=\"p\">).</span><span class=\"n\">to_csv</span><span class=\"p\">(</span><span class=\"s\">\"job_postings_results.csv\"</span><span class=\"p\">)</span></code></pre></figure>",
      "excerpt": "Each website is built by different individuals so there is no one magic script that can scrape different websites because the art of scraping lies in deconstructing the html elements into separate objects that we can extract or “scrape” the information from. Of course there are scraping tools out there that automate these scripts based on your preference (literally google free web scraping tools, there are a bunch of them). I have tried several of these tools and I always end up getting frustrated and going back to writing the codes myself because a) they always have a pricing tier despite claiming to be free, and b) the process is overcomplicated and some websites are just not built intuitively that these tools can easily automate. This tutorial specifies the necessary steps to scrape data from Jobstreet Malaysia but the process of crawling and scraping boils down to a few basic steps that can be applied to almost any website.",
      "languages": null,
      "categories": ["projects"],
      "tags": ["projects,","web","crawling,","web","scraping,","selenium,","python"]
    }
    
  

  
    ,
    {
      "title": "Tokyo State of Mind",
      "permalink": "http://0.0.0.0:4321/tokyo-state-of-mind.html",
      "link": "http://0.0.0.0:4321/tokyo-state-of-mind.html",
      "date": "2020-12-24T00:00:00+08:00",
      
        "modified": "2021-04-15T23:42:55+08:00",
      
      "author": {
        "name": "Naelah Nordin",
        "url": "https://naelahnordin.com/",
        "email": "naelahnordin@gmail.com"
      },
      "content": "<p>Sometimes people ask me how was it like in Japan? And I often find it hard to answer because my experience with Japan spans a few years starting when my dad worked there for a couple of years</p>\n\n<p>When I try to recall Japan, I get flashes of memories. Getting on the wrong express train platform and going the opposite direction and trying to go on the right direction but realizing too late that express trains and normal trains share the same tracks and a supposedly 1 hour trip ended up being 3 hours. Seeing my dad after a year and seeing how his wrinkles are more prominent and his hair is turning whiter and it hit me how much time spent apart is time wasted not being together.</p>\n\n<h2 id=\"the-process\">The Process</h2>\n<p>The process of marriage is very simple. Boy meets girl. Boy &amp; girl like each other. Boy meets girl’s parents. Register marr</p>\n\n<h2 id=\"the-process-1\">The Process</h2>\n\n<h2 id=\"the-problem\">The Problem</h2>",
      "excerpt": "Sometimes people ask me how was it like in Japan? And I often find it hard to answer because my experience with Japan spans a few years starting when my dad worked there for a couple of years",
      "languages": null,
      "categories": ["journal"],
      "tags": ["journal,","personal,","travel"]
    }
    
  

  
    ,
    {
      "title": "Visualizing Malaysian Cinema",
      "permalink": "http://0.0.0.0:4321/visualizing-malaysian-cinema.html",
      "link": "http://0.0.0.0:4321/visualizing-malaysian-cinema.html",
      "date": "2020-11-12T00:00:00+08:00",
      
        "modified": "2021-04-15T23:46:41+08:00",
      
      "author": {
        "name": "Naelah Nordin",
        "url": "https://naelahnordin.com/",
        "email": "naelahnordin@gmail.com"
      },
      "content": "<!-- ---\nlayout: post\ntitle: Visualizing 20 years of Malay Cinema\n#category: projects\ntags: projects, data visualization, d3.js\ndesc: Using Apply lambda function to loop through each row in a dataframe\n---\n\n## The Problem -->",
      "excerpt": "&lt;!– —\nlayout: post\ntitle: Visualizing 20 years of Malay Cinema\n#category: projects\ntags: projects, data visualization, d3.js\ndesc: Using Apply lambda function to loop through each row in a dataframe\n—",
      "languages": null,
      "categories": [],
      "tags": []
    }
    
  

  
    ,
    {
      "title": "Ebilikguru",
      "permalink": "http://0.0.0.0:4321/eBilikGuru.html",
      "link": "http://0.0.0.0:4321/eBilikGuru.html",
      "date": "2020-10-01T00:00:00+08:00",
      
        "modified": "2021-04-15T23:45:20+08:00",
      
      "author": {
        "name": "Naelah Nordin",
        "url": "https://naelahnordin.com/",
        "email": "naelahnordin@gmail.com"
      },
      "content": "",
      "excerpt": "",
      "languages": null,
      "categories": [],
      "tags": []
    }
    
  

  
    ,
    {
      "title": "Aduh   pothole reporting app",
      "permalink": "http://0.0.0.0:4321/Aduh-Pothole-Reporting-App.html",
      "link": "http://0.0.0.0:4321/Aduh-Pothole-Reporting-App.html",
      "date": "2020-09-30T00:00:00+08:00",
      
        "modified": "2021-04-15T23:45:15+08:00",
      
      "author": {
        "name": "Naelah Nordin",
        "url": "https://naelahnordin.com/",
        "email": "naelahnordin@gmail.com"
      },
      "content": "",
      "excerpt": "",
      "languages": null,
      "categories": [],
      "tags": []
    }
    
  

  
    ,
    {
      "title": "Mapping Two Dataframes In Python",
      "permalink": "http://0.0.0.0:4321/mapping-two-dataframes-in-python.html",
      "link": "http://0.0.0.0:4321/mapping-two-dataframes-in-python.html",
      "date": "2020-09-20T00:00:00+08:00",
      
        "modified": "2021-04-15T23:46:33+08:00",
      
      "author": {
        "name": "Naelah Nordin",
        "url": "https://naelahnordin.com/",
        "email": "naelahnordin@gmail.com"
      },
      "content": "<!-- ---\nlayout: post\ntitle: Mapping Data in Python\n#category: notes\ntags: notes, python, programming, pandas, dataframe, mapping\ndesc: Mapping two dataframes with a matching value in a single column\n\n\n---\n\n\n## The Problem\nYou have two dataframes with a single column that links both with common data. For example a dataframe containing \n```python\n\n\n```\n\n## The Solution\n\n\n -->",
      "excerpt": "&lt;!– —\nlayout: post\ntitle: Mapping Data in Python\n#category: notes\ntags: notes, python, programming, pandas, dataframe, mapping\ndesc: Mapping two dataframes with a matching value in a single column",
      "languages": null,
      "categories": [],
      "tags": []
    }
    
  

  
    ,
    {
      "title": "Iterations in Python",
      "permalink": "http://0.0.0.0:4321/using-apply-lambda-in-python.html",
      "link": "http://0.0.0.0:4321/using-apply-lambda-in-python.html",
      "date": "2020-08-01T00:00:00+08:00",
      
        "modified": "2021-04-16T13:11:20+08:00",
      
      "author": {
        "name": "Naelah Nordin",
        "url": "https://naelahnordin.com/",
        "email": "naelahnordin@gmail.com"
      },
      "content": "<h1 id=\"using-apply-for-single-column\">Using apply for single column</h1>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">'new_column] = df['</span><span class=\"n\">column</span><span class=\"s\">'].apply(lambda x: something(x))</span></code></pre></figure>\n\n<h1 id=\"using-apply-for-a-whole-row\">Using apply for a whole row</h1>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">'new_column] = df['</span><span class=\"n\">column</span><span class=\"s\">'].apply(lambda x: something(x))</span></code></pre></figure>\n\n<h1 id=\"fixed-iteration\">Fixed iteration</h1>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">'new_column] = df['</span><span class=\"n\">column</span><span class=\"s\">'].apply(lambda x: something(x))</span></code></pre></figure>\n\n<h1 id=\"having-index-of-row\">Having index of row</h1>\n\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"s\">'new_column] = df['</span><span class=\"n\">column</span><span class=\"s\">'].apply(lambda x: something(x))</span></code></pre></figure>",
      "excerpt": "Using apply for single column",
      "languages": null,
      "categories": ["notes"],
      "tags": ["notes,","python,","programming,","pandas,","dataframe,","apply,","lambda"]
    }
    
  

  
    ,
    {
      "title": "The Royal Wedding",
      "permalink": "http://0.0.0.0:4321/the-royal-wedding.html",
      "link": "http://0.0.0.0:4321/the-royal-wedding.html",
      "date": "2018-04-01T00:00:00+08:00",
      
        "modified": "2021-04-15T23:43:22+08:00",
      
      "author": {
        "name": "Naelah Nordin",
        "url": "https://naelahnordin.com/",
        "email": "naelahnordin@gmail.com"
      },
      "content": "<p>Getting married is a big step into adulthood. It’s not quite a big deal depending on your circumstances but it’s a huge life decision. Nevertheless it could be the easiest decision you ever make. \nYou look at a person and you go, “I don’t mind spending my life with that person.” Spending time together feels easy, being in each other’s presence is effortless and you’re both co-existing in each other’s spaces without wanting or needing something in return. You simply exist.</p>\n\n<p>I’m an introvert so physical social interactions normally exhaust me after a certain period of time. There are times even when I felt like hanging out is a chore so if I want to hangout with you, that’s a big deal. If I want to spend the rest of my life with you, that’s mega big deal 5000. Regardless, finding a person you can live with is just one variable of the whole equation. There’s so many hoops and loops to jump through to get in that binding contract and as much as it was worth every effort, it was still pretty damn exhausting. Getting legally married is one thing but planning the wedding reception is a whole different monstrosity altogether.</p>\n\n<h2 id=\"the-process\">The Process</h2>\n<p>The process of marriage is very simple. Boy meets girl. Boy &amp; girl like each other. Boy meets girl’s parents. Register marr</p>\n\n<h2 id=\"the-process-1\">The Process</h2>\n\n<h2 id=\"the-problem\">The Problem</h2>",
      "excerpt": "Getting married is a big step into adulthood. It’s not quite a big deal depending on your circumstances but it’s a huge life decision. Nevertheless it could be the easiest decision you ever make. \nYou look at a person and you go, “I don’t mind spending my life with that person.” Spending time together feels easy, being in each other’s presence is effortless and you’re both co-existing in each other’s spaces without wanting or needing something in return. You simply exist.",
      "languages": null,
      "categories": ["journal"],
      "tags": ["journal,","personal,","family"]
    }
    
  

  
    ,
    {
      "title": "Game Addiction Diagnosis User Interface",
      "permalink": "http://0.0.0.0:4321/Game-Addiction-Diagnosis-User-Interface.html",
      "link": "http://0.0.0.0:4321/Game-Addiction-Diagnosis-User-Interface.html",
      "date": "2017-10-12T00:00:00+08:00",
      
        "modified": "2021-04-15T23:45:11+08:00",
      
      "author": {
        "name": "Naelah Nordin",
        "url": "https://naelahnordin.com/",
        "email": "naelahnordin@gmail.com"
      },
      "content": "",
      "excerpt": "",
      "languages": null,
      "categories": [],
      "tags": []
    }
    
  


]
